{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab79674",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install typing-inspect==0.8.0 typing_extensions==4.5.0\n",
    "!pip install pydantic==1.10.11\n",
    "# !pip install llama-cpp-python\n",
    "# !pip install tensorflow\n",
    "!pip install accelerate\n",
    "!pip install bitsandbytes\n",
    "!pip install -U tokenizers\n",
    "!pip install transformers\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c00759",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ctransformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22fd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler \n",
    "\n",
    "callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "config_sql = {'max_new_tokens': 512, 'repetition_penalty': 1.1,'temperature':0,'stop':[';']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a877e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"example.db\"\n",
    "try: \n",
    "    conn = sqlite3.connect(file) \n",
    "    print(f\"Database {file} formed.\") \n",
    "except: \n",
    "    print(f\"Database {file} not formed.\")\n",
    "\n",
    "with sqlite3.connect(file) as conn:\n",
    "    try:\n",
    "        df.to_sql('df',conn,if_exists='replace',index=False)\n",
    "        print('df table created')\n",
    "    except:\n",
    "        print('df table not created')\n",
    "        \n",
    "con = sqlite3.connect(\"example.db\")\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query(question):\n",
    "    prompt=f\"\"\"\n",
    "    {context}\n",
    "    Question: Write a sql query for the question '{question}'\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    llm = CTransformers(model='openorca-platypus2-13b.Q4_K_M.gguf', \n",
    "                        config=config_sql,callback_manager=callback_manager)\n",
    "    return llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760587d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\n",
    "query_result = generate_sql_query(question)\n",
    "with sqlite3.connect(file) as conn:\n",
    "    df_result = pd.read_sql_query(query_result, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document \n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS,Chroma\n",
    "\n",
    "class vectorstore:\n",
    "    def __init__(self,sheet_name):\n",
    "        self.sheet_name = sheet_name\n",
    "        self.df = pd.read_excel('All_Files.xlsx',sheet_name = sheet_name)\n",
    "        self.df = self.df.fillna('No Data')\n",
    "        self.df = self.df.astype(str)\n",
    "        \n",
    "        self.columns_to_embed = self.df.columns.values\n",
    "        self.columns_to_metadata = self.df.columns.values\n",
    "\n",
    "        self.df_columns_to_embed=self.df[self.columns_to_embed]\n",
    "        self.df_columns_to_metadata=self.df[self.columns_to_metadata]\n",
    "\n",
    "        self.to_embed_dict=self.df_columns_to_embed.to_dict('records')\n",
    "        self.to_metadata_dict=self.df_columns_to_metadata.to_dict('records')\n",
    "   \n",
    "    def load_documents(self):\n",
    "        # Define the columns we want to embed vs which ones we want in metadata\n",
    "        self.docs=[]\n",
    "        for i in range(len(self.to_embed_dict)):\n",
    "            to_embed = self.to_embed_dict[i]\n",
    "            to_metadata = self.to_metadata_dict[i]\n",
    "            to_embed = \"\\n\".join(f\"{k.strip()}: {v.strip()}\" for k, v in to_embed.items())\n",
    "            newDoc=Document(page_content=to_embed,metadata=to_metadata)\n",
    "            self.docs.append(newDoc)\n",
    "\n",
    "    def document_splitter(self):\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
    "        self.docs = text_splitter.split_documents(self.docs)\n",
    "\n",
    "    def save_embedding(self):\n",
    "        self.hf = HuggingFaceEmbeddings()\n",
    "        self.db = FAISS.from_documents(self.docs, self.hf)\n",
    "        self.db.save_local(f\"faiss_index_{self.sheet_name}\")\n",
    "        print(f'{self.sheet_name} saved')\n",
    "\n",
    "    def embedding_load_and_search(self,query,num_of_matches):\n",
    "        self.hf = HuggingFaceEmbeddings()\n",
    "        self.db = FAISS.load_local(f\"faiss_index_{self.sheet_name}\", self.hf)\n",
    "        df_result = pd.DataFrame(data=[],columns=self.columns_to_metadata)\n",
    "\n",
    "        results = self.db.similarity_search(query,k=num_of_matches)\n",
    "        for i in range (len(results)):\n",
    "            df_embed_result = pd.DataFrame([results[i].metadata])\n",
    "            df_result = pd.concat([df_result,df_embed_result],axis=0,ignore_index=True)\n",
    "\n",
    "        return df_result\n",
    "    \n",
    "    def load_split_save(self):\n",
    "        self.load_documents()\n",
    "        self.document_splitter()\n",
    "        self.save_embedding()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
